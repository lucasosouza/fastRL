{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Sarsa and Q-Learning\n",
    "### FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../agents')\n",
    "sys.path.append('../environments')\n",
    "sys.path.append('../tools')\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from MonteCarlo import MonteCarloEV, MonteCarloFV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize env\n",
    "env = Experiment(gym.make('FrozenLake-v0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Every Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tries =3\n",
    "episodes = 2000\n",
    "results_MonteCarloEV = np.zeros((tries, episodes))\n",
    "epsilon_decay = 1-(1/episodes)*2\n",
    "\n",
    "for t in range(tries):\n",
    "    agent = MonteCarloEV(env.env, discount_factor=0.9, \n",
    "                      exploration_rate=0.8,\n",
    "                      epsilon_decay_func = lambda x: x*epsilon_decay,\n",
    "                      qtable_default=0\n",
    "                     )\n",
    "    # fit and save results\n",
    "    env.fit(agent, episodes)\n",
    "    results_MonteCarloEV[t, :] = agent.rewards_per_episode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo First Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tries =3\n",
    "episodes = 2000\n",
    "results_MonteCarloFV = np.zeros((tries, episodes))\n",
    "epsilon_decay = 1-(1/episodes)*2\n",
    "\n",
    "for t in range(tries):\n",
    "    agent = MonteCarloFV(env.env, discount_factor=0.9, \n",
    "                      exploration_rate=0.8,\n",
    "                      epsilon_decay_func = lambda x: x*epsilon_decay,\n",
    "                      qtable_default=0\n",
    "                     )\n",
    "    # fit and save results\n",
    "    env.fit(agent, episodes)\n",
    "    results_MonteCarloFV[t, :] = agent.rewards_per_episode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3x10000 episodes, qtable default = 0\n",
    "plot_rewards(np.mean(results_MonteCarloEV, axis=0), smoothing=0.4, color='green')\n",
    "plot_rewards(np.mean(results_MonteCarloFV, axis=0), smoothing=0.4, color='blue')\n",
    "plt.ylim((0,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the smoothing parameter, it is clear Monte Carlo Every Visit outperforms the First Visit up to 3000 episodes. Te result is similar even when the results are ran again, with action-value function initiated to 0 or to 1.\n",
    "\n",
    "Every visit has more samples to update from than the first visit version, so it learns faster. This is clearly seen when compared to the Q-Learning algorithm that bootstraps though the value function to help estimate future returns, so is able to do policy improvement at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:udacity]",
   "language": "python",
   "name": "conda-env-udacity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
